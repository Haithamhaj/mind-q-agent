# Mind-Q Agent

An intelligent local knowledge management system that combines graph databases, vector embeddings, and NLP to build a personal knowledge graph from your files.

## ğŸ¯ Overview

Mind-Q Agent is a production-quality knowledge management system that:
- Monitors local files and extracts knowledge automatically
- Builds a semantic knowledge graph using KÃ¹zuDB
- Creates vector embeddings for intelligent search using ChromaDB
- Uses NLP (spaCy) for entity extraction and relationship detection
- Implements Hebbian learning for strengthening connections

## ğŸ—ï¸ Architecture

```
File Watcher â†’ Text Extraction â†’ Entity Extraction â†’ Graph + Vector Storage â†’ Search
```

### Technology Stack

- **Python 3.10+** - Core language
- **KÃ¹zuDB** - High-performance embedded graph database
- **ChromaDB** - Vector database for semantic search
- **spaCy** - NLP and entity extraction
- **sentence-transformers** - Text embeddings
- **watchdog** - File system monitoring

## ğŸ“ Project Structure

```
mind-q-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ graph/         # KÃ¹zuDB interface
â”‚   â”œâ”€â”€ vector/        # ChromaDB interface
â”‚   â”œâ”€â”€ extraction/    # Entity extraction
â”‚   â”œâ”€â”€ watcher/       # File system monitoring
â”‚   â”œâ”€â”€ learning/      # Hebbian learning
â”‚   â”œâ”€â”€ query/         # Search engine
â”‚   â””â”€â”€ utils/         # Utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/          # Unit tests
â”‚   â””â”€â”€ integration/   # Integration tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ graph/         # Graph database storage
â”‚   â”œâ”€â”€ vectors/       # Vector storage
â”‚   â”œâ”€â”€ uploads/       # Input files
â”‚   â””â”€â”€ outputs/       # Generated outputs
â”œâ”€â”€ config/            # Configuration files
â””â”€â”€ docs/              # Documentation
```

## ğŸš€ Setup

### 1. Clone and Navigate
```bash
cd /Users/haitham/development/mind-q-agent
```

### 2. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Download spaCy Model
```bash
python -m spacy download en_core_web_sm
```

## ğŸ§ª Development

### Run Tests
```bash
pytest tests/ -v --cov=src
```

### Code Formatting
```bash
black src/ tests/
ruff check src/ tests/
```

### Using Aider (AI Pair Programming)
```bash
aider --model gemini/gemini-2.0-flash-exp
```

## ğŸ“ Development Phases

Development follows a phase-by-phase approach with testing after each task:

1. **Phase 1**: Core Infrastructure (Graph + Vector DB interfaces)
2. **Phase 2**: File Watching & Text Extraction
3. **Phase 3**: Entity Extraction & NLP
4. **Phase 4**: Hebbian Learning
5. **Phase 5**: Query & Search Engine
6. **Phase 6**: Discovery & Insights

## ğŸ¤ Contributing

This is a personal project, but contributions and suggestions are welcome!

## ğŸ“„ License

MIT License

---

**Status**: ğŸš§ In Development
